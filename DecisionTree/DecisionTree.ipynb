{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树：寻找划分数据集的最好标签\n",
    "       划分数据集\n",
    "       创建分支节点\n",
    "       在每个划分的子集中：寻找最好的标签继续划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    featureNames = ['no surfacing','flippers'] #不浮出水面是否存活 ，有无脚蹼\n",
    "    #change to discrete values\n",
    "    return dataSet, featureNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、对标签列求信息熵\n",
    "熵：信息的期望值\n",
    "信息的定义：l(xi) = -log(P(xi))\n",
    "熵：H(x) = - sum[P(xi)log(P(xi))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dataset):\n",
    "    num = len(dataset)\n",
    "    labelSets = {}\n",
    "    for fec in dataset:\n",
    "        currentLabel = fec[-1]\n",
    "        if currentLabel not in labelSets.keys():\n",
    "            labelSets[currentLabel] = 0\n",
    "        labelSets[currentLabel] += 1\n",
    "    \n",
    "    entropy = 0.0\n",
    "    for key in labelSets:\n",
    "        prob = float(labelSets[key]) / num  #P(xi)\n",
    "        entropy = - prob * math.log2(prob)   #这里不求熵，因为没有求和\n",
    "#         print('key:{}'.format(key),'value:{}'.format(labelSets[key]),entropy)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵越高，表明数据越混乱,不确定性就越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "0.44217935649972373\n"
     ]
    }
   ],
   "source": [
    "data,fec = createDataSet()\n",
    "print(data)\n",
    "my_entropy = entropy(data)\n",
    "print(my_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、按获取最大信息增益，选取最好的数据集划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataset,axis,value):\n",
    "    returnDataset = []\n",
    "    for i in dataset:\n",
    "        if i[axis] == value:\n",
    "            tmp = i[:axis]\n",
    "            tmp.extend(i[axis+1:]) #1,yes\n",
    "            returnDataset.append(tmp)\n",
    "    return returnDataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data,fec = createDataSet()\n",
    "resu = splitDataSet(data,0,1)  #axis = 0,且这个值为1\n",
    "print(resu)\n",
    "print(len(resu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看哪个特征划分使得信息熵(数据无序度)减小的最多  ---最佳分割特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFec(dataset):\n",
    "    numFec = len(dataset[0]) -1  #最后的标签列去除\n",
    "    baseEntropy = entropy(dataset)  #原始信息熵\n",
    "    bestInfoGain = 0.0;bestFeature = -1\n",
    "    for i in range(numFec):\n",
    "        featureList = [ex[i] for ex in dataset]\n",
    "        uniqueFec = set(featureList)  #去重\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueFec:\n",
    "            subData = splitDataSet(dataset,i,value)#对第i个特征，针对某个值划分\n",
    "#             print('sub:{}'.format(subData))\n",
    "            prob = len(subData) / float(len(dataset))\n",
    "            newEntropy += prob * entropy(subData)\n",
    "        \n",
    "        infoGain = baseEntropy - newEntropy  #信息增益\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain   #替换好的\n",
    "            bestFeature = i   \n",
    "    return bestFeature            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "index = chooseBestFec(data)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "找出list中出现次数最多的\n",
    "对字典排序，取得最大值：将多数的类别标签作为叶子节点的类别\n",
    "'''\n",
    "def majority(list):\n",
    "    return np.argmax(np.bincount(list))\n",
    "\n",
    "#测试\n",
    "c = [1,1,1,0,0,2,2,2,2,3,3,3,3,3,3,3,3]\n",
    "print(majority(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据数据集合，创建一个完整的决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,featureNames):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList): #如果所有的类都一样，第0类的个数==长度\n",
    "        return classList[0]#stop splitting when all of the classes are equal\n",
    "    if len(dataSet[0]) == 1: #stop splitting when there are no more features in dataSet\n",
    "        return majorityCnt(classList) #如果所有的特征都被遍历用于划分数据\n",
    "    bestFeature = chooseBestFec(dataSet)\n",
    "    bestFeatureName = featureNames[bestFeature]\n",
    "    myTree = {bestFeatureName:{}} #用字典存储树结构\n",
    "    del(featureNames[bestFeature]) #从特征名称列表中删除这个bestFeatureName\n",
    "    featureValues = [example[bestFeature] for example in dataSet]  #遍历最好的特征的取值，进行划分\n",
    "    uniqueVals = set(featureValues)\n",
    "    for value in uniqueVals:\n",
    "        subNames = featureNames[:]  #copy all of featureName, 为了保留原有的featureName不被函数修改\n",
    "        myTree[bestFeatureName][value] = \\\n",
    "            createTree(splitDataSet(dataSet, bestFeature, value),subNames) #返回的是一个字典\n",
    "    return myTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = createTree(data,fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
